{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n",
      "2.9.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "print(tf.__version__)\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(123)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "Porównaj wyniki działań różnych optymalizacji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9232/2985883500.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  train_set = pd.read_csv('https://raw.githubusercontent.com/przem85/podstawy_sztucznej_inteligencji/main/Dane/adult/adult.data', sep=\", \",header = None)\n",
      "/tmp/ipykernel_9232/2985883500.py:7: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  test_set = pd.read_csv('https://raw.githubusercontent.com/przem85/podstawy_sztucznej_inteligencji/main/Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n"
     ]
    },
    {
     "data": {
      "text/plain": "   age         workclass  fnlwgt  education  education_num  \\\n0   39         State-gov   77516  Bachelors             13   \n1   50  Self-emp-not-inc   83311  Bachelors             13   \n2   38           Private  215646    HS-grad              9   \n3   53           Private  234721       11th              7   \n4   28           Private  338409  Bachelors             13   \n\n       marital_status         occupation   relationship   race     sex  \\\n0       Never-married       Adm-clerical  Not-in-family  White    Male   \n1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n\n   capital_gain  capital_loss  hours_per_week native_country wage_class  \n0          2174             0              40  United-States      <=50K  \n1             0             0              13  United-States      <=50K  \n2             0             0              40  United-States      <=50K  \n3             0             0              40  United-States      <=50K  \n4             0             0              40           Cuba      <=50K  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>workclass</th>\n      <th>fnlwgt</th>\n      <th>education</th>\n      <th>education_num</th>\n      <th>marital_status</th>\n      <th>occupation</th>\n      <th>relationship</th>\n      <th>race</th>\n      <th>sex</th>\n      <th>capital_gain</th>\n      <th>capital_loss</th>\n      <th>hours_per_week</th>\n      <th>native_country</th>\n      <th>wage_class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>State-gov</td>\n      <td>77516</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Never-married</td>\n      <td>Adm-clerical</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>2174</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>50</td>\n      <td>Self-emp-not-inc</td>\n      <td>83311</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Exec-managerial</td>\n      <td>Husband</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>13</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>38</td>\n      <td>Private</td>\n      <td>215646</td>\n      <td>HS-grad</td>\n      <td>9</td>\n      <td>Divorced</td>\n      <td>Handlers-cleaners</td>\n      <td>Not-in-family</td>\n      <td>White</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>53</td>\n      <td>Private</td>\n      <td>234721</td>\n      <td>11th</td>\n      <td>7</td>\n      <td>Married-civ-spouse</td>\n      <td>Handlers-cleaners</td>\n      <td>Husband</td>\n      <td>Black</td>\n      <td>Male</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>United-States</td>\n      <td>&lt;=50K</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>28</td>\n      <td>Private</td>\n      <td>338409</td>\n      <td>Bachelors</td>\n      <td>13</td>\n      <td>Married-civ-spouse</td>\n      <td>Prof-specialty</td>\n      <td>Wife</td>\n      <td>Black</td>\n      <td>Female</td>\n      <td>0</td>\n      <td>0</td>\n      <td>40</td>\n      <td>Cuba</td>\n      <td>&lt;=50K</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wczytaj dane treningowe i testowe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "train_set = pd.read_csv('https://raw.githubusercontent.com/przem85/podstawy_sztucznej_inteligencji/main/Dane/adult/adult.data', sep=\", \",header = None)\n",
    "test_set = pd.read_csv('https://raw.githubusercontent.com/przem85/podstawy_sztucznej_inteligencji/main/Dane/adult/adult.test', sep=\", \",skiprows = 1, header = None) # Make sure to skip a row for the test set\n",
    "\n",
    "col_labels = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', \n",
    "              'relationship', 'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country',\n",
    "             'wage_class']\n",
    "train_set.columns = col_labels\n",
    "test_set.columns = col_labels\n",
    "\n",
    "train = train_set.replace('?', np.nan).dropna()\n",
    "test = test_set.replace('?', np.nan).dropna()\n",
    "\n",
    "train_set.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30162, 41)\n"
     ]
    },
    {
     "data": {
      "text/plain": "(15060, 41)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([train,test])\n",
    "\n",
    "dataset['wage_class'] = dataset.wage_class.replace({'<=50K.': 0,'<=50K':0, '>50K.':1, '>50K':1})\n",
    "\n",
    "dataset.drop(['fnlwgt'],axis=1,inplace=True)\n",
    "\n",
    "dataset.drop([\"education\"],axis=1,inplace=True)\n",
    "\n",
    "x = dataset.groupby('native_country')[\"wage_class\"].mean()\n",
    "\n",
    "d = dict(pd.cut(x[x.index!=\" United-States\"],5,labels=range(5)))\n",
    "\n",
    "dataset['native_country'] = dataset['native_country'].replace(d)\n",
    "\n",
    "dataset = pd.get_dummies(dataset,drop_first=True)\n",
    "\n",
    "train = dataset.iloc[:train.shape[0]]\n",
    "test = dataset.iloc[train.shape[0]:]\n",
    "\n",
    "X_train = train.drop(\"wage_class\",axis=1)\n",
    "y_train = train.wage_class\n",
    "\n",
    "X_test = test.drop(\"wage_class\",axis=1)\n",
    "y_test = test.wage_class\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               4200      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 17:05:59.095988: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-25 17:05:59.096054: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-25 17:05:59.096508: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hania-dell): /proc/driver/nvidia/version does not exist\n",
      "2022-05-25 17:05:59.099791: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.callbacks import History\n",
    "\n",
    "history_sgd = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = keras.optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=sgd, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.5231 - accuracy: 0.7536 - val_loss: 0.3939 - val_accuracy: 0.8120\n",
      "Epoch 2/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3530 - accuracy: 0.8358 - val_loss: 0.3395 - val_accuracy: 0.8411\n",
      "Epoch 3/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3369 - accuracy: 0.8418 - val_loss: 0.3345 - val_accuracy: 0.8441\n",
      "Epoch 4/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3314 - accuracy: 0.8447 - val_loss: 0.3310 - val_accuracy: 0.8454\n",
      "Epoch 5/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3288 - accuracy: 0.8456 - val_loss: 0.3395 - val_accuracy: 0.8359\n",
      "Epoch 6/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3284 - accuracy: 0.8460 - val_loss: 0.3280 - val_accuracy: 0.8465\n",
      "Epoch 7/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3270 - accuracy: 0.8473 - val_loss: 0.3381 - val_accuracy: 0.8378\n",
      "Epoch 8/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3259 - accuracy: 0.8473 - val_loss: 0.3268 - val_accuracy: 0.8461\n",
      "Epoch 9/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3257 - accuracy: 0.8474 - val_loss: 0.3274 - val_accuracy: 0.8466\n",
      "Epoch 10/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3243 - accuracy: 0.8487 - val_loss: 0.3299 - val_accuracy: 0.8454\n",
      "Epoch 11/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3241 - accuracy: 0.8476 - val_loss: 0.3273 - val_accuracy: 0.8449\n",
      "Epoch 12/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3226 - accuracy: 0.8483 - val_loss: 0.3248 - val_accuracy: 0.8471\n",
      "Epoch 13/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3220 - accuracy: 0.8493 - val_loss: 0.3242 - val_accuracy: 0.8481\n",
      "Epoch 14/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3219 - accuracy: 0.8486 - val_loss: 0.3258 - val_accuracy: 0.8477\n",
      "Epoch 15/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3208 - accuracy: 0.8499 - val_loss: 0.3257 - val_accuracy: 0.8475\n",
      "Epoch 16/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3199 - accuracy: 0.8504 - val_loss: 0.3227 - val_accuracy: 0.8475\n",
      "Epoch 17/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3194 - accuracy: 0.8493 - val_loss: 0.3306 - val_accuracy: 0.8420\n",
      "Epoch 18/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3194 - accuracy: 0.8499 - val_loss: 0.3215 - val_accuracy: 0.8488\n",
      "Epoch 19/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3187 - accuracy: 0.8499 - val_loss: 0.3245 - val_accuracy: 0.8481\n",
      "Epoch 20/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3181 - accuracy: 0.8505 - val_loss: 0.3217 - val_accuracy: 0.8491\n",
      "Epoch 21/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3176 - accuracy: 0.8505 - val_loss: 0.3212 - val_accuracy: 0.8496\n",
      "Epoch 22/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3168 - accuracy: 0.8515 - val_loss: 0.3203 - val_accuracy: 0.8499\n",
      "Epoch 23/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3166 - accuracy: 0.8509 - val_loss: 0.3213 - val_accuracy: 0.8504\n",
      "Epoch 24/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3162 - accuracy: 0.8521 - val_loss: 0.3204 - val_accuracy: 0.8496\n",
      "Epoch 25/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3158 - accuracy: 0.8520 - val_loss: 0.3223 - val_accuracy: 0.8479\n",
      "Epoch 26/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3152 - accuracy: 0.8521 - val_loss: 0.3213 - val_accuracy: 0.8502\n",
      "Epoch 27/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3147 - accuracy: 0.8517 - val_loss: 0.3210 - val_accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3137 - accuracy: 0.8522 - val_loss: 0.3211 - val_accuracy: 0.8507\n",
      "Epoch 29/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3139 - accuracy: 0.8519 - val_loss: 0.3212 - val_accuracy: 0.8483\n",
      "Epoch 30/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3130 - accuracy: 0.8521 - val_loss: 0.3219 - val_accuracy: 0.8505\n",
      "Epoch 31/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3130 - accuracy: 0.8537 - val_loss: 0.3198 - val_accuracy: 0.8511\n",
      "Epoch 32/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3124 - accuracy: 0.8533 - val_loss: 0.3194 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3117 - accuracy: 0.8529 - val_loss: 0.3215 - val_accuracy: 0.8491\n",
      "Epoch 34/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3114 - accuracy: 0.8539 - val_loss: 0.3186 - val_accuracy: 0.8509\n",
      "Epoch 35/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3111 - accuracy: 0.8546 - val_loss: 0.3216 - val_accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3107 - accuracy: 0.8544 - val_loss: 0.3180 - val_accuracy: 0.8509\n",
      "Epoch 37/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3101 - accuracy: 0.8541 - val_loss: 0.3184 - val_accuracy: 0.8508\n",
      "Epoch 38/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3096 - accuracy: 0.8534 - val_loss: 0.3174 - val_accuracy: 0.8516\n",
      "Epoch 39/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3088 - accuracy: 0.8556 - val_loss: 0.3196 - val_accuracy: 0.8493\n",
      "Epoch 40/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3090 - accuracy: 0.8552 - val_loss: 0.3181 - val_accuracy: 0.8505\n",
      "Epoch 41/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3086 - accuracy: 0.8552 - val_loss: 0.3197 - val_accuracy: 0.8510\n",
      "Epoch 42/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3084 - accuracy: 0.8559 - val_loss: 0.3197 - val_accuracy: 0.8505\n",
      "Epoch 43/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3079 - accuracy: 0.8570 - val_loss: 0.3236 - val_accuracy: 0.8463\n",
      "Epoch 44/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3082 - accuracy: 0.8547 - val_loss: 0.3197 - val_accuracy: 0.8513\n",
      "Epoch 45/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3075 - accuracy: 0.8569 - val_loss: 0.3189 - val_accuracy: 0.8515\n",
      "Epoch 46/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3067 - accuracy: 0.8558 - val_loss: 0.3206 - val_accuracy: 0.8491\n",
      "Epoch 47/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3068 - accuracy: 0.8558 - val_loss: 0.3184 - val_accuracy: 0.8515\n",
      "Epoch 48/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3059 - accuracy: 0.8573 - val_loss: 0.3199 - val_accuracy: 0.8495\n",
      "Epoch 49/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3063 - accuracy: 0.8561 - val_loss: 0.3202 - val_accuracy: 0.8489\n",
      "Epoch 50/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3058 - accuracy: 0.8575 - val_loss: 0.3203 - val_accuracy: 0.8499\n",
      "Epoch 51/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3056 - accuracy: 0.8572 - val_loss: 0.3184 - val_accuracy: 0.8507\n",
      "Epoch 52/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3050 - accuracy: 0.8575 - val_loss: 0.3195 - val_accuracy: 0.8517\n",
      "Epoch 53/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3052 - accuracy: 0.8566 - val_loss: 0.3219 - val_accuracy: 0.8500\n",
      "Epoch 54/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3049 - accuracy: 0.8567 - val_loss: 0.3248 - val_accuracy: 0.8494\n",
      "Epoch 55/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3044 - accuracy: 0.8575 - val_loss: 0.3185 - val_accuracy: 0.8499\n",
      "Epoch 56/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3045 - accuracy: 0.8564 - val_loss: 0.3197 - val_accuracy: 0.8506\n",
      "Epoch 57/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3039 - accuracy: 0.8584 - val_loss: 0.3197 - val_accuracy: 0.8495\n",
      "Epoch 58/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3037 - accuracy: 0.8576 - val_loss: 0.3202 - val_accuracy: 0.8529\n",
      "Epoch 59/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3031 - accuracy: 0.8583 - val_loss: 0.3217 - val_accuracy: 0.8497\n",
      "Epoch 60/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3032 - accuracy: 0.8576 - val_loss: 0.3209 - val_accuracy: 0.8503\n",
      "Epoch 61/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3028 - accuracy: 0.8594 - val_loss: 0.3196 - val_accuracy: 0.8499\n",
      "Epoch 62/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3025 - accuracy: 0.8583 - val_loss: 0.3219 - val_accuracy: 0.8509\n",
      "Epoch 63/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3024 - accuracy: 0.8594 - val_loss: 0.3213 - val_accuracy: 0.8489\n",
      "Epoch 64/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3019 - accuracy: 0.8585 - val_loss: 0.3280 - val_accuracy: 0.8422\n",
      "Epoch 65/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3020 - accuracy: 0.8575 - val_loss: 0.3223 - val_accuracy: 0.8478\n",
      "Epoch 66/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3020 - accuracy: 0.8590 - val_loss: 0.3207 - val_accuracy: 0.8501\n",
      "Epoch 67/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3014 - accuracy: 0.8588 - val_loss: 0.3272 - val_accuracy: 0.8495\n",
      "Epoch 68/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3009 - accuracy: 0.8594 - val_loss: 0.3220 - val_accuracy: 0.8516\n",
      "Epoch 69/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3007 - accuracy: 0.8595 - val_loss: 0.3231 - val_accuracy: 0.8495\n",
      "Epoch 70/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3010 - accuracy: 0.8579 - val_loss: 0.3213 - val_accuracy: 0.8493\n",
      "Epoch 71/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3005 - accuracy: 0.8594 - val_loss: 0.3232 - val_accuracy: 0.8489\n",
      "Epoch 72/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3003 - accuracy: 0.8596 - val_loss: 0.3234 - val_accuracy: 0.8498\n",
      "Epoch 73/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3000 - accuracy: 0.8602 - val_loss: 0.3218 - val_accuracy: 0.8501\n",
      "Epoch 74/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2999 - accuracy: 0.8592 - val_loss: 0.3227 - val_accuracy: 0.8511\n",
      "Epoch 75/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2992 - accuracy: 0.8602 - val_loss: 0.3224 - val_accuracy: 0.8503\n",
      "Epoch 76/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2991 - accuracy: 0.8602 - val_loss: 0.3235 - val_accuracy: 0.8499\n",
      "Epoch 77/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2985 - accuracy: 0.8600 - val_loss: 0.3232 - val_accuracy: 0.8489\n",
      "Epoch 78/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2988 - accuracy: 0.8590 - val_loss: 0.3239 - val_accuracy: 0.8486\n",
      "Epoch 79/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2983 - accuracy: 0.8609 - val_loss: 0.3254 - val_accuracy: 0.8511\n",
      "Epoch 80/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2985 - accuracy: 0.8604 - val_loss: 0.3315 - val_accuracy: 0.8423\n",
      "Epoch 81/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2983 - accuracy: 0.8601 - val_loss: 0.3264 - val_accuracy: 0.8476\n",
      "Epoch 82/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2977 - accuracy: 0.8606 - val_loss: 0.3248 - val_accuracy: 0.8494\n",
      "Epoch 83/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2973 - accuracy: 0.8606 - val_loss: 0.3266 - val_accuracy: 0.8491\n",
      "Epoch 84/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2972 - accuracy: 0.8612 - val_loss: 0.3247 - val_accuracy: 0.8502\n",
      "Epoch 85/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2967 - accuracy: 0.8617 - val_loss: 0.3269 - val_accuracy: 0.8494\n",
      "Epoch 86/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2965 - accuracy: 0.8609 - val_loss: 0.3259 - val_accuracy: 0.8484\n",
      "Epoch 87/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2961 - accuracy: 0.8625 - val_loss: 0.3275 - val_accuracy: 0.8471\n",
      "Epoch 88/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2961 - accuracy: 0.8616 - val_loss: 0.3281 - val_accuracy: 0.8489\n",
      "Epoch 89/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2961 - accuracy: 0.8619 - val_loss: 0.3252 - val_accuracy: 0.8497\n",
      "Epoch 90/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2959 - accuracy: 0.8610 - val_loss: 0.3251 - val_accuracy: 0.8481\n",
      "Epoch 91/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2955 - accuracy: 0.8617 - val_loss: 0.3259 - val_accuracy: 0.8494\n",
      "Epoch 92/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2951 - accuracy: 0.8612 - val_loss: 0.3299 - val_accuracy: 0.8450\n",
      "Epoch 93/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2945 - accuracy: 0.8624 - val_loss: 0.3272 - val_accuracy: 0.8504\n",
      "Epoch 94/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2948 - accuracy: 0.8618 - val_loss: 0.3275 - val_accuracy: 0.8479\n",
      "Epoch 95/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2948 - accuracy: 0.8618 - val_loss: 0.3284 - val_accuracy: 0.8483\n",
      "Epoch 96/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2944 - accuracy: 0.8630 - val_loss: 0.3294 - val_accuracy: 0.8483\n",
      "Epoch 97/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2940 - accuracy: 0.8631 - val_loss: 0.3307 - val_accuracy: 0.8490\n",
      "Epoch 98/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2938 - accuracy: 0.8623 - val_loss: 0.3280 - val_accuracy: 0.8476\n",
      "Epoch 99/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2929 - accuracy: 0.8631 - val_loss: 0.3296 - val_accuracy: 0.8493\n",
      "Epoch 100/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2934 - accuracy: 0.8630 - val_loss: 0.3333 - val_accuracy: 0.8485\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f0320c23100>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[history_sgd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_sgd.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "plt.plot(history_sgd.history['accuracy'], label = \"tarina\")\n",
    "plt.plot(history_sgd.history['val_accuracy'], label = \"test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Użyjmy LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 100)               4200      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                510       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5701 - accuracy: 0.7378 - val_loss: 0.5541 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5559 - accuracy: 0.7511 - val_loss: 0.5503 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5515 - accuracy: 0.7511 - val_loss: 0.5450 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5449 - accuracy: 0.7511 - val_loss: 0.5377 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5345 - accuracy: 0.7511 - val_loss: 0.5238 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5169 - accuracy: 0.7511 - val_loss: 0.5018 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4879 - accuracy: 0.7511 - val_loss: 0.4661 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4474 - accuracy: 0.7586 - val_loss: 0.4236 - val_accuracy: 0.7819 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4076 - accuracy: 0.8029 - val_loss: 0.3892 - val_accuracy: 0.8164 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3853 - accuracy: 0.8245 - val_loss: 0.3776 - val_accuracy: 0.8258 - lr: 0.0050\n",
      "Epoch 11/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3751 - accuracy: 0.8301 - val_loss: 0.3689 - val_accuracy: 0.8303 - lr: 0.0050\n",
      "Epoch 12/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3675 - accuracy: 0.8322 - val_loss: 0.3626 - val_accuracy: 0.8349 - lr: 0.0050\n",
      "Epoch 13/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3619 - accuracy: 0.8332 - val_loss: 0.3579 - val_accuracy: 0.8358 - lr: 0.0050\n",
      "Epoch 14/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3576 - accuracy: 0.8342 - val_loss: 0.3544 - val_accuracy: 0.8373 - lr: 0.0050\n",
      "Epoch 15/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3544 - accuracy: 0.8349 - val_loss: 0.3517 - val_accuracy: 0.8364 - lr: 0.0050\n",
      "Epoch 16/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3518 - accuracy: 0.8356 - val_loss: 0.3495 - val_accuracy: 0.8369 - lr: 0.0050\n",
      "Epoch 17/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3497 - accuracy: 0.8364 - val_loss: 0.3479 - val_accuracy: 0.8366 - lr: 0.0050\n",
      "Epoch 18/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3481 - accuracy: 0.8366 - val_loss: 0.3465 - val_accuracy: 0.8382 - lr: 0.0050\n",
      "Epoch 19/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3465 - accuracy: 0.8371 - val_loss: 0.3455 - val_accuracy: 0.8392 - lr: 0.0050\n",
      "Epoch 20/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3455 - accuracy: 0.8375 - val_loss: 0.3451 - val_accuracy: 0.8392 - lr: 0.0025\n",
      "Epoch 21/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3449 - accuracy: 0.8374 - val_loss: 0.3444 - val_accuracy: 0.8393 - lr: 0.0025\n",
      "Epoch 22/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3443 - accuracy: 0.8377 - val_loss: 0.3439 - val_accuracy: 0.8392 - lr: 0.0025\n",
      "Epoch 23/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3438 - accuracy: 0.8382 - val_loss: 0.3435 - val_accuracy: 0.8396 - lr: 0.0025\n",
      "Epoch 24/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3433 - accuracy: 0.8379 - val_loss: 0.3431 - val_accuracy: 0.8393 - lr: 0.0025\n",
      "Epoch 25/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3428 - accuracy: 0.8382 - val_loss: 0.3427 - val_accuracy: 0.8402 - lr: 0.0025\n",
      "Epoch 26/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3424 - accuracy: 0.8386 - val_loss: 0.3424 - val_accuracy: 0.8408 - lr: 0.0025\n",
      "Epoch 27/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3420 - accuracy: 0.8383 - val_loss: 0.3421 - val_accuracy: 0.8400 - lr: 0.0025\n",
      "Epoch 28/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3416 - accuracy: 0.8385 - val_loss: 0.3417 - val_accuracy: 0.8406 - lr: 0.0025\n",
      "Epoch 29/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3412 - accuracy: 0.8385 - val_loss: 0.3414 - val_accuracy: 0.8408 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3408 - accuracy: 0.8387 - val_loss: 0.3413 - val_accuracy: 0.8407 - lr: 0.0012\n",
      "Epoch 31/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3407 - accuracy: 0.8392 - val_loss: 0.3412 - val_accuracy: 0.8404 - lr: 0.0012\n",
      "Epoch 32/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3404 - accuracy: 0.8391 - val_loss: 0.3412 - val_accuracy: 0.8394 - lr: 0.0012\n",
      "Epoch 33/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3403 - accuracy: 0.8390 - val_loss: 0.3409 - val_accuracy: 0.8406 - lr: 0.0012\n",
      "Epoch 34/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3401 - accuracy: 0.8397 - val_loss: 0.3408 - val_accuracy: 0.8402 - lr: 0.0012\n",
      "Epoch 35/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3399 - accuracy: 0.8394 - val_loss: 0.3406 - val_accuracy: 0.8406 - lr: 0.0012\n",
      "Epoch 36/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8394 - val_loss: 0.3405 - val_accuracy: 0.8406 - lr: 0.0012\n",
      "Epoch 37/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8399 - val_loss: 0.3403 - val_accuracy: 0.8403 - lr: 0.0012\n",
      "Epoch 38/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3394 - accuracy: 0.8397 - val_loss: 0.3402 - val_accuracy: 0.8410 - lr: 0.0012\n",
      "Epoch 39/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3393 - accuracy: 0.8401 - val_loss: 0.3402 - val_accuracy: 0.8400 - lr: 0.0012\n",
      "Epoch 40/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3391 - accuracy: 0.8396 - val_loss: 0.3401 - val_accuracy: 0.8406 - lr: 6.2500e-04\n",
      "Epoch 41/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3390 - accuracy: 0.8402 - val_loss: 0.3400 - val_accuracy: 0.8406 - lr: 6.2500e-04\n",
      "Epoch 42/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3390 - accuracy: 0.8402 - val_loss: 0.3399 - val_accuracy: 0.8404 - lr: 6.2500e-04\n",
      "Epoch 43/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3389 - accuracy: 0.8400 - val_loss: 0.3399 - val_accuracy: 0.8404 - lr: 6.2500e-04\n",
      "Epoch 44/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3388 - accuracy: 0.8401 - val_loss: 0.3398 - val_accuracy: 0.8404 - lr: 6.2500e-04\n",
      "Epoch 45/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3387 - accuracy: 0.8401 - val_loss: 0.3398 - val_accuracy: 0.8404 - lr: 6.2500e-04\n",
      "Epoch 46/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3387 - accuracy: 0.8402 - val_loss: 0.3397 - val_accuracy: 0.8404 - lr: 6.2500e-04\n",
      "Epoch 47/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3386 - accuracy: 0.8400 - val_loss: 0.3397 - val_accuracy: 0.8403 - lr: 6.2500e-04\n",
      "Epoch 48/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3385 - accuracy: 0.8403 - val_loss: 0.3396 - val_accuracy: 0.8403 - lr: 6.2500e-04\n",
      "Epoch 49/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3384 - accuracy: 0.8404 - val_loss: 0.3395 - val_accuracy: 0.8405 - lr: 6.2500e-04\n",
      "Epoch 50/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3384 - accuracy: 0.8403 - val_loss: 0.3395 - val_accuracy: 0.8404 - lr: 3.1250e-04\n",
      "Epoch 51/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3383 - accuracy: 0.8405 - val_loss: 0.3395 - val_accuracy: 0.8404 - lr: 3.1250e-04\n",
      "Epoch 52/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3383 - accuracy: 0.8405 - val_loss: 0.3394 - val_accuracy: 0.8408 - lr: 3.1250e-04\n",
      "Epoch 53/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3383 - accuracy: 0.8405 - val_loss: 0.3394 - val_accuracy: 0.8404 - lr: 3.1250e-04\n",
      "Epoch 54/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3382 - accuracy: 0.8405 - val_loss: 0.3394 - val_accuracy: 0.8403 - lr: 3.1250e-04\n",
      "Epoch 55/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3382 - accuracy: 0.8405 - val_loss: 0.3394 - val_accuracy: 0.8403 - lr: 3.1250e-04\n",
      "Epoch 56/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3381 - accuracy: 0.8405 - val_loss: 0.3393 - val_accuracy: 0.8403 - lr: 3.1250e-04\n",
      "Epoch 57/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3381 - accuracy: 0.8406 - val_loss: 0.3393 - val_accuracy: 0.8404 - lr: 3.1250e-04\n",
      "Epoch 58/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3381 - accuracy: 0.8405 - val_loss: 0.3393 - val_accuracy: 0.8406 - lr: 3.1250e-04\n",
      "Epoch 59/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3380 - accuracy: 0.8405 - val_loss: 0.3393 - val_accuracy: 0.8405 - lr: 3.1250e-04\n",
      "Epoch 60/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3380 - accuracy: 0.8406 - val_loss: 0.3392 - val_accuracy: 0.8406 - lr: 1.5625e-04\n",
      "Epoch 61/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3380 - accuracy: 0.8407 - val_loss: 0.3392 - val_accuracy: 0.8407 - lr: 1.5625e-04\n",
      "Epoch 62/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3380 - accuracy: 0.8404 - val_loss: 0.3392 - val_accuracy: 0.8407 - lr: 1.5625e-04\n",
      "Epoch 63/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3379 - accuracy: 0.8406 - val_loss: 0.3392 - val_accuracy: 0.8407 - lr: 1.5625e-04\n",
      "Epoch 64/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3379 - accuracy: 0.8406 - val_loss: 0.3392 - val_accuracy: 0.8407 - lr: 1.5625e-04\n",
      "Epoch 65/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3379 - accuracy: 0.8406 - val_loss: 0.3392 - val_accuracy: 0.8407 - lr: 1.5625e-04\n",
      "Epoch 66/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3379 - accuracy: 0.8405 - val_loss: 0.3392 - val_accuracy: 0.8408 - lr: 1.5625e-04\n",
      "Epoch 67/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3379 - accuracy: 0.8407 - val_loss: 0.3391 - val_accuracy: 0.8408 - lr: 1.5625e-04\n",
      "Epoch 68/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3379 - accuracy: 0.8406 - val_loss: 0.3391 - val_accuracy: 0.8408 - lr: 1.5625e-04\n",
      "Epoch 69/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8406 - val_loss: 0.3391 - val_accuracy: 0.8410 - lr: 1.5625e-04\n",
      "Epoch 70/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8407 - val_loss: 0.3391 - val_accuracy: 0.8410 - lr: 7.8125e-05\n",
      "Epoch 71/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8406 - val_loss: 0.3391 - val_accuracy: 0.8410 - lr: 7.8125e-05\n",
      "Epoch 72/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8406 - val_loss: 0.3391 - val_accuracy: 0.8410 - lr: 7.8125e-05\n",
      "Epoch 73/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8407 - val_loss: 0.3391 - val_accuracy: 0.8410 - lr: 7.8125e-05\n",
      "Epoch 74/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8406 - val_loss: 0.3391 - val_accuracy: 0.8410 - lr: 7.8125e-05\n",
      "Epoch 75/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8407 - val_loss: 0.3391 - val_accuracy: 0.8410 - lr: 7.8125e-05\n",
      "Epoch 76/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8406 - val_loss: 0.3391 - val_accuracy: 0.8411 - lr: 7.8125e-05\n",
      "Epoch 77/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8406 - val_loss: 0.3391 - val_accuracy: 0.8411 - lr: 7.8125e-05\n",
      "Epoch 78/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3378 - accuracy: 0.8406 - val_loss: 0.3391 - val_accuracy: 0.8411 - lr: 7.8125e-05\n",
      "Epoch 79/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8407 - val_loss: 0.3391 - val_accuracy: 0.8411 - lr: 7.8125e-05\n",
      "Epoch 80/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8407 - val_loss: 0.3391 - val_accuracy: 0.8410 - lr: 3.9062e-05\n",
      "Epoch 81/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8410 - lr: 3.9062e-05\n",
      "Epoch 82/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8407 - val_loss: 0.3390 - val_accuracy: 0.8411 - lr: 3.9062e-05\n",
      "Epoch 83/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8411 - lr: 3.9062e-05\n",
      "Epoch 84/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8410 - lr: 3.9062e-05\n",
      "Epoch 85/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8410 - lr: 3.9062e-05\n",
      "Epoch 86/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8410 - lr: 3.9062e-05\n",
      "Epoch 87/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8405 - val_loss: 0.3390 - val_accuracy: 0.8410 - lr: 3.9062e-05\n",
      "Epoch 88/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8410 - lr: 3.9062e-05\n",
      "Epoch 89/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8410 - lr: 3.9062e-05\n",
      "Epoch 90/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8410 - lr: 1.9531e-05\n",
      "Epoch 91/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8407 - val_loss: 0.3390 - val_accuracy: 0.8411 - lr: 1.9531e-05\n",
      "Epoch 92/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8412 - lr: 1.9531e-05\n",
      "Epoch 93/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8405 - val_loss: 0.3390 - val_accuracy: 0.8412 - lr: 1.9531e-05\n",
      "Epoch 94/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8412 - lr: 1.9531e-05\n",
      "Epoch 95/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8412 - lr: 1.9531e-05\n",
      "Epoch 96/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8407 - val_loss: 0.3390 - val_accuracy: 0.8412 - lr: 1.9531e-05\n",
      "Epoch 97/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8406 - val_loss: 0.3390 - val_accuracy: 0.8412 - lr: 1.9531e-05\n",
      "Epoch 98/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8407 - val_loss: 0.3390 - val_accuracy: 0.8412 - lr: 1.9531e-05\n",
      "Epoch 99/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8407 - val_loss: 0.3390 - val_accuracy: 0.8412 - lr: 1.9531e-05\n",
      "Epoch 100/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3377 - accuracy: 0.8407 - val_loss: 0.3390 - val_accuracy: 0.8412 - lr: 9.7656e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f031463e410>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    lrate = initial_lrate * np.power(drop, np.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "history_lr_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "# sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate, history_lr_1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "plt.plot(history_sgd.history['accuracy'], label = \"tarina\")\n",
    "plt.plot(history_sgd.history['val_accuracy'], label = \"test\")\n",
    "\n",
    "plt.plot(history_lr_1.history['accuracy'], label = \"tarina LR\")\n",
    "plt.plot(history_lr_1.history['val_accuracy'], label = \"test LR\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zad\n",
    "\n",
    "Wykonaj analogiczne zadanie dla \n",
    "* Adam bez LearningRateScheduler i learning_rate=0.001\n",
    "* Adam z użyciem LearningRateScheduler i learning_rate=0.001\n",
    "* Adam z użyciem LearningRateScheduler i learning_rate=0.0001\n",
    "\n",
    "Zwizualizuj wyniki:\n",
    "\n",
    "* porównaj krzywe uczenia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             (None, 100)               4200      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "943/943 [==============================] - 3s 2ms/step - loss: 0.3722 - accuracy: 0.8252 - val_loss: 0.3506 - val_accuracy: 0.8292\n",
      "Epoch 2/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3348 - accuracy: 0.8451 - val_loss: 0.3344 - val_accuracy: 0.8461\n",
      "Epoch 3/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3276 - accuracy: 0.8478 - val_loss: 0.3266 - val_accuracy: 0.8475\n",
      "Epoch 4/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3243 - accuracy: 0.8475 - val_loss: 0.3257 - val_accuracy: 0.8486\n",
      "Epoch 5/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3233 - accuracy: 0.8488 - val_loss: 0.3238 - val_accuracy: 0.8490\n",
      "Epoch 6/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3217 - accuracy: 0.8502 - val_loss: 0.3250 - val_accuracy: 0.8481\n",
      "Epoch 7/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3200 - accuracy: 0.8504 - val_loss: 0.3232 - val_accuracy: 0.8480\n",
      "Epoch 8/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3188 - accuracy: 0.8512 - val_loss: 0.3239 - val_accuracy: 0.8476\n",
      "Epoch 9/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3177 - accuracy: 0.8511 - val_loss: 0.3257 - val_accuracy: 0.8472\n",
      "Epoch 10/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3163 - accuracy: 0.8517 - val_loss: 0.3202 - val_accuracy: 0.8508\n",
      "Epoch 11/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3146 - accuracy: 0.8526 - val_loss: 0.3187 - val_accuracy: 0.8526\n",
      "Epoch 12/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3138 - accuracy: 0.8521 - val_loss: 0.3203 - val_accuracy: 0.8497\n",
      "Epoch 13/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3122 - accuracy: 0.8534 - val_loss: 0.3202 - val_accuracy: 0.8483\n",
      "Epoch 14/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3112 - accuracy: 0.8538 - val_loss: 0.3183 - val_accuracy: 0.8509\n",
      "Epoch 15/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3102 - accuracy: 0.8545 - val_loss: 0.3189 - val_accuracy: 0.8501\n",
      "Epoch 16/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3098 - accuracy: 0.8549 - val_loss: 0.3175 - val_accuracy: 0.8509\n",
      "Epoch 17/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3082 - accuracy: 0.8543 - val_loss: 0.3185 - val_accuracy: 0.8508\n",
      "Epoch 18/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3082 - accuracy: 0.8550 - val_loss: 0.3220 - val_accuracy: 0.8460\n",
      "Epoch 19/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3071 - accuracy: 0.8561 - val_loss: 0.3192 - val_accuracy: 0.8509\n",
      "Epoch 20/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3061 - accuracy: 0.8562 - val_loss: 0.3191 - val_accuracy: 0.8503\n",
      "Epoch 21/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3057 - accuracy: 0.8558 - val_loss: 0.3177 - val_accuracy: 0.8500\n",
      "Epoch 22/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3045 - accuracy: 0.8570 - val_loss: 0.3224 - val_accuracy: 0.8510\n",
      "Epoch 23/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3034 - accuracy: 0.8575 - val_loss: 0.3180 - val_accuracy: 0.8499\n",
      "Epoch 24/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3027 - accuracy: 0.8573 - val_loss: 0.3183 - val_accuracy: 0.8507\n",
      "Epoch 25/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3018 - accuracy: 0.8583 - val_loss: 0.3173 - val_accuracy: 0.8519\n",
      "Epoch 26/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3011 - accuracy: 0.8586 - val_loss: 0.3251 - val_accuracy: 0.8503\n",
      "Epoch 27/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2995 - accuracy: 0.8596 - val_loss: 0.3204 - val_accuracy: 0.8503\n",
      "Epoch 28/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2985 - accuracy: 0.8598 - val_loss: 0.3181 - val_accuracy: 0.8507\n",
      "Epoch 29/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2972 - accuracy: 0.8602 - val_loss: 0.3186 - val_accuracy: 0.8497\n",
      "Epoch 30/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2963 - accuracy: 0.8613 - val_loss: 0.3173 - val_accuracy: 0.8516\n",
      "Epoch 31/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2949 - accuracy: 0.8625 - val_loss: 0.3211 - val_accuracy: 0.8491\n",
      "Epoch 32/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2943 - accuracy: 0.8626 - val_loss: 0.3194 - val_accuracy: 0.8508\n",
      "Epoch 33/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2933 - accuracy: 0.8630 - val_loss: 0.3196 - val_accuracy: 0.8509\n",
      "Epoch 34/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2921 - accuracy: 0.8632 - val_loss: 0.3194 - val_accuracy: 0.8531\n",
      "Epoch 35/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2912 - accuracy: 0.8636 - val_loss: 0.3223 - val_accuracy: 0.8491\n",
      "Epoch 36/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2905 - accuracy: 0.8631 - val_loss: 0.3180 - val_accuracy: 0.8525\n",
      "Epoch 37/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2889 - accuracy: 0.8645 - val_loss: 0.3231 - val_accuracy: 0.8518\n",
      "Epoch 38/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2888 - accuracy: 0.8653 - val_loss: 0.3190 - val_accuracy: 0.8519\n",
      "Epoch 39/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2881 - accuracy: 0.8656 - val_loss: 0.3198 - val_accuracy: 0.8531\n",
      "Epoch 40/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2873 - accuracy: 0.8640 - val_loss: 0.3229 - val_accuracy: 0.8512\n",
      "Epoch 41/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2860 - accuracy: 0.8662 - val_loss: 0.3214 - val_accuracy: 0.8516\n",
      "Epoch 42/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2850 - accuracy: 0.8663 - val_loss: 0.3239 - val_accuracy: 0.8520\n",
      "Epoch 43/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2845 - accuracy: 0.8664 - val_loss: 0.3260 - val_accuracy: 0.8488\n",
      "Epoch 44/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2833 - accuracy: 0.8670 - val_loss: 0.3236 - val_accuracy: 0.8509\n",
      "Epoch 45/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2825 - accuracy: 0.8677 - val_loss: 0.3249 - val_accuracy: 0.8515\n",
      "Epoch 46/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2815 - accuracy: 0.8670 - val_loss: 0.3289 - val_accuracy: 0.8503\n",
      "Epoch 47/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2814 - accuracy: 0.8685 - val_loss: 0.3255 - val_accuracy: 0.8517\n",
      "Epoch 48/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2802 - accuracy: 0.8677 - val_loss: 0.3311 - val_accuracy: 0.8511\n",
      "Epoch 49/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2795 - accuracy: 0.8680 - val_loss: 0.3279 - val_accuracy: 0.8503\n",
      "Epoch 50/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2786 - accuracy: 0.8692 - val_loss: 0.3306 - val_accuracy: 0.8492\n",
      "Epoch 51/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2776 - accuracy: 0.8696 - val_loss: 0.3328 - val_accuracy: 0.8512\n",
      "Epoch 52/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2772 - accuracy: 0.8690 - val_loss: 0.3319 - val_accuracy: 0.8501\n",
      "Epoch 53/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2763 - accuracy: 0.8708 - val_loss: 0.3408 - val_accuracy: 0.8458\n",
      "Epoch 54/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2753 - accuracy: 0.8692 - val_loss: 0.3358 - val_accuracy: 0.8502\n",
      "Epoch 55/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2748 - accuracy: 0.8698 - val_loss: 0.3348 - val_accuracy: 0.8468\n",
      "Epoch 56/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2741 - accuracy: 0.8700 - val_loss: 0.3351 - val_accuracy: 0.8504\n",
      "Epoch 57/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2735 - accuracy: 0.8713 - val_loss: 0.3343 - val_accuracy: 0.8498\n",
      "Epoch 58/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2719 - accuracy: 0.8707 - val_loss: 0.3432 - val_accuracy: 0.8486\n",
      "Epoch 59/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2718 - accuracy: 0.8722 - val_loss: 0.3363 - val_accuracy: 0.8494\n",
      "Epoch 60/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2705 - accuracy: 0.8721 - val_loss: 0.3421 - val_accuracy: 0.8493\n",
      "Epoch 61/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2705 - accuracy: 0.8720 - val_loss: 0.3500 - val_accuracy: 0.8427\n",
      "Epoch 62/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2697 - accuracy: 0.8729 - val_loss: 0.3470 - val_accuracy: 0.8430\n",
      "Epoch 63/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2689 - accuracy: 0.8726 - val_loss: 0.3416 - val_accuracy: 0.8485\n",
      "Epoch 64/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2683 - accuracy: 0.8736 - val_loss: 0.3527 - val_accuracy: 0.8478\n",
      "Epoch 65/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2680 - accuracy: 0.8738 - val_loss: 0.3449 - val_accuracy: 0.8480\n",
      "Epoch 66/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2667 - accuracy: 0.8733 - val_loss: 0.3451 - val_accuracy: 0.8473\n",
      "Epoch 67/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2659 - accuracy: 0.8745 - val_loss: 0.3473 - val_accuracy: 0.8480\n",
      "Epoch 68/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2652 - accuracy: 0.8755 - val_loss: 0.3447 - val_accuracy: 0.8473\n",
      "Epoch 69/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2647 - accuracy: 0.8748 - val_loss: 0.3472 - val_accuracy: 0.8471\n",
      "Epoch 70/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2642 - accuracy: 0.8743 - val_loss: 0.3487 - val_accuracy: 0.8491\n",
      "Epoch 71/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2634 - accuracy: 0.8753 - val_loss: 0.3571 - val_accuracy: 0.8473\n",
      "Epoch 72/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2622 - accuracy: 0.8760 - val_loss: 0.3546 - val_accuracy: 0.8463\n",
      "Epoch 73/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2624 - accuracy: 0.8760 - val_loss: 0.3544 - val_accuracy: 0.8461\n",
      "Epoch 74/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2616 - accuracy: 0.8755 - val_loss: 0.3601 - val_accuracy: 0.8453\n",
      "Epoch 75/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2608 - accuracy: 0.8767 - val_loss: 0.3695 - val_accuracy: 0.8461\n",
      "Epoch 76/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2602 - accuracy: 0.8768 - val_loss: 0.3592 - val_accuracy: 0.8447\n",
      "Epoch 77/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2592 - accuracy: 0.8774 - val_loss: 0.3609 - val_accuracy: 0.8487\n",
      "Epoch 78/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2590 - accuracy: 0.8783 - val_loss: 0.3664 - val_accuracy: 0.8428\n",
      "Epoch 79/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2575 - accuracy: 0.8768 - val_loss: 0.3621 - val_accuracy: 0.8450\n",
      "Epoch 80/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2575 - accuracy: 0.8775 - val_loss: 0.3629 - val_accuracy: 0.8430\n",
      "Epoch 81/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2565 - accuracy: 0.8785 - val_loss: 0.3673 - val_accuracy: 0.8434\n",
      "Epoch 82/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2564 - accuracy: 0.8780 - val_loss: 0.3665 - val_accuracy: 0.8468\n",
      "Epoch 83/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2557 - accuracy: 0.8788 - val_loss: 0.3689 - val_accuracy: 0.8438\n",
      "Epoch 84/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2553 - accuracy: 0.8792 - val_loss: 0.3696 - val_accuracy: 0.8447\n",
      "Epoch 85/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2542 - accuracy: 0.8790 - val_loss: 0.3763 - val_accuracy: 0.8446\n",
      "Epoch 86/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2541 - accuracy: 0.8796 - val_loss: 0.3712 - val_accuracy: 0.8459\n",
      "Epoch 87/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2529 - accuracy: 0.8801 - val_loss: 0.3770 - val_accuracy: 0.8416\n",
      "Epoch 88/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2526 - accuracy: 0.8805 - val_loss: 0.3752 - val_accuracy: 0.8479\n",
      "Epoch 89/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2522 - accuracy: 0.8794 - val_loss: 0.3821 - val_accuracy: 0.8470\n",
      "Epoch 90/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2513 - accuracy: 0.8809 - val_loss: 0.3778 - val_accuracy: 0.8463\n",
      "Epoch 91/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2508 - accuracy: 0.8800 - val_loss: 0.3851 - val_accuracy: 0.8458\n",
      "Epoch 92/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2501 - accuracy: 0.8813 - val_loss: 0.3864 - val_accuracy: 0.8414\n",
      "Epoch 93/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2501 - accuracy: 0.8807 - val_loss: 0.3879 - val_accuracy: 0.8469\n",
      "Epoch 94/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2489 - accuracy: 0.8820 - val_loss: 0.3856 - val_accuracy: 0.8449\n",
      "Epoch 95/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2487 - accuracy: 0.8806 - val_loss: 0.3838 - val_accuracy: 0.8452\n",
      "Epoch 96/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2478 - accuracy: 0.8822 - val_loss: 0.3872 - val_accuracy: 0.8447\n",
      "Epoch 97/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2473 - accuracy: 0.8825 - val_loss: 0.3920 - val_accuracy: 0.8415\n",
      "Epoch 98/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2472 - accuracy: 0.8828 - val_loss: 0.3903 - val_accuracy: 0.8438\n",
      "Epoch 99/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2466 - accuracy: 0.8823 - val_loss: 0.3906 - val_accuracy: 0.8451\n",
      "Epoch 100/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.2452 - accuracy: 0.8820 - val_loss: 0.3964 - val_accuracy: 0.8453\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f03146936d0>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_lr_1 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "adam1 = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=adam1, metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[history_lr_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 100)               4200      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "943/943 [==============================] - 3s 2ms/step - loss: 0.5737 - accuracy: 0.7376 - val_loss: 0.5573 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5593 - accuracy: 0.7511 - val_loss: 0.5544 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5565 - accuracy: 0.7511 - val_loss: 0.5515 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5532 - accuracy: 0.7511 - val_loss: 0.5478 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5484 - accuracy: 0.7511 - val_loss: 0.5421 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5413 - accuracy: 0.7511 - val_loss: 0.5333 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5297 - accuracy: 0.7511 - val_loss: 0.5186 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.5096 - accuracy: 0.7511 - val_loss: 0.4934 - val_accuracy: 0.7543 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4768 - accuracy: 0.7513 - val_loss: 0.4539 - val_accuracy: 0.7572 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4446 - accuracy: 0.7592 - val_loss: 0.4318 - val_accuracy: 0.7694 - lr: 0.0050\n",
      "Epoch 11/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4228 - accuracy: 0.7848 - val_loss: 0.4112 - val_accuracy: 0.7970 - lr: 0.0050\n",
      "Epoch 12/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.4035 - accuracy: 0.8109 - val_loss: 0.3942 - val_accuracy: 0.8212 - lr: 0.0050\n",
      "Epoch 13/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3883 - accuracy: 0.8266 - val_loss: 0.3809 - val_accuracy: 0.8284 - lr: 0.0050\n",
      "Epoch 14/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3768 - accuracy: 0.8305 - val_loss: 0.3713 - val_accuracy: 0.8304 - lr: 0.0050\n",
      "Epoch 15/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3685 - accuracy: 0.8312 - val_loss: 0.3645 - val_accuracy: 0.8356 - lr: 0.0050\n",
      "Epoch 16/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3625 - accuracy: 0.8332 - val_loss: 0.3595 - val_accuracy: 0.8369 - lr: 0.0050\n",
      "Epoch 17/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3581 - accuracy: 0.8335 - val_loss: 0.3557 - val_accuracy: 0.8377 - lr: 0.0050\n",
      "Epoch 18/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3547 - accuracy: 0.8350 - val_loss: 0.3529 - val_accuracy: 0.8384 - lr: 0.0050\n",
      "Epoch 19/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3522 - accuracy: 0.8355 - val_loss: 0.3507 - val_accuracy: 0.8373 - lr: 0.0050\n",
      "Epoch 20/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3504 - accuracy: 0.8355 - val_loss: 0.3499 - val_accuracy: 0.8371 - lr: 0.0025\n",
      "Epoch 21/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3495 - accuracy: 0.8362 - val_loss: 0.3490 - val_accuracy: 0.8376 - lr: 0.0025\n",
      "Epoch 22/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3486 - accuracy: 0.8365 - val_loss: 0.3482 - val_accuracy: 0.8384 - lr: 0.0025\n",
      "Epoch 23/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3478 - accuracy: 0.8368 - val_loss: 0.3475 - val_accuracy: 0.8387 - lr: 0.0025\n",
      "Epoch 24/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3470 - accuracy: 0.8371 - val_loss: 0.3468 - val_accuracy: 0.8390 - lr: 0.0025\n",
      "Epoch 25/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3464 - accuracy: 0.8372 - val_loss: 0.3464 - val_accuracy: 0.8379 - lr: 0.0025\n",
      "Epoch 26/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3457 - accuracy: 0.8377 - val_loss: 0.3457 - val_accuracy: 0.8386 - lr: 0.0025\n",
      "Epoch 27/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3451 - accuracy: 0.8376 - val_loss: 0.3452 - val_accuracy: 0.8396 - lr: 0.0025\n",
      "Epoch 28/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3446 - accuracy: 0.8380 - val_loss: 0.3447 - val_accuracy: 0.8402 - lr: 0.0025\n",
      "Epoch 29/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3440 - accuracy: 0.8386 - val_loss: 0.3443 - val_accuracy: 0.8389 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3436 - accuracy: 0.8384 - val_loss: 0.3440 - val_accuracy: 0.8398 - lr: 0.0012\n",
      "Epoch 31/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3434 - accuracy: 0.8389 - val_loss: 0.3438 - val_accuracy: 0.8394 - lr: 0.0012\n",
      "Epoch 32/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3431 - accuracy: 0.8392 - val_loss: 0.3437 - val_accuracy: 0.8390 - lr: 0.0012\n",
      "Epoch 33/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3428 - accuracy: 0.8395 - val_loss: 0.3437 - val_accuracy: 0.8380 - lr: 0.0012\n",
      "Epoch 34/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3427 - accuracy: 0.8393 - val_loss: 0.3433 - val_accuracy: 0.8392 - lr: 0.0012\n",
      "Epoch 35/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3424 - accuracy: 0.8395 - val_loss: 0.3431 - val_accuracy: 0.8395 - lr: 0.0012\n",
      "Epoch 36/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3422 - accuracy: 0.8399 - val_loss: 0.3429 - val_accuracy: 0.8394 - lr: 0.0012\n",
      "Epoch 37/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3420 - accuracy: 0.8392 - val_loss: 0.3427 - val_accuracy: 0.8406 - lr: 0.0012\n",
      "Epoch 38/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3418 - accuracy: 0.8397 - val_loss: 0.3425 - val_accuracy: 0.8404 - lr: 0.0012\n",
      "Epoch 39/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3416 - accuracy: 0.8394 - val_loss: 0.3423 - val_accuracy: 0.8406 - lr: 0.0012\n",
      "Epoch 40/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3414 - accuracy: 0.8400 - val_loss: 0.3423 - val_accuracy: 0.8402 - lr: 6.2500e-04\n",
      "Epoch 41/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3413 - accuracy: 0.8397 - val_loss: 0.3422 - val_accuracy: 0.8402 - lr: 6.2500e-04\n",
      "Epoch 42/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3412 - accuracy: 0.8399 - val_loss: 0.3421 - val_accuracy: 0.8400 - lr: 6.2500e-04\n",
      "Epoch 43/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3411 - accuracy: 0.8396 - val_loss: 0.3420 - val_accuracy: 0.8405 - lr: 6.2500e-04\n",
      "Epoch 44/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3410 - accuracy: 0.8400 - val_loss: 0.3420 - val_accuracy: 0.8403 - lr: 6.2500e-04\n",
      "Epoch 45/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3409 - accuracy: 0.8401 - val_loss: 0.3419 - val_accuracy: 0.8396 - lr: 6.2500e-04\n",
      "Epoch 46/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3408 - accuracy: 0.8396 - val_loss: 0.3418 - val_accuracy: 0.8404 - lr: 6.2500e-04\n",
      "Epoch 47/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3407 - accuracy: 0.8402 - val_loss: 0.3417 - val_accuracy: 0.8395 - lr: 6.2500e-04\n",
      "Epoch 48/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3406 - accuracy: 0.8401 - val_loss: 0.3416 - val_accuracy: 0.8398 - lr: 6.2500e-04\n",
      "Epoch 49/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3405 - accuracy: 0.8400 - val_loss: 0.3416 - val_accuracy: 0.8400 - lr: 6.2500e-04\n",
      "Epoch 50/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3405 - accuracy: 0.8403 - val_loss: 0.3415 - val_accuracy: 0.8400 - lr: 3.1250e-04\n",
      "Epoch 51/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3404 - accuracy: 0.8402 - val_loss: 0.3415 - val_accuracy: 0.8397 - lr: 3.1250e-04\n",
      "Epoch 52/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3404 - accuracy: 0.8399 - val_loss: 0.3414 - val_accuracy: 0.8400 - lr: 3.1250e-04\n",
      "Epoch 53/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3403 - accuracy: 0.8401 - val_loss: 0.3414 - val_accuracy: 0.8399 - lr: 3.1250e-04\n",
      "Epoch 54/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3403 - accuracy: 0.8402 - val_loss: 0.3414 - val_accuracy: 0.8398 - lr: 3.1250e-04\n",
      "Epoch 55/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3402 - accuracy: 0.8404 - val_loss: 0.3413 - val_accuracy: 0.8398 - lr: 3.1250e-04\n",
      "Epoch 56/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3402 - accuracy: 0.8404 - val_loss: 0.3413 - val_accuracy: 0.8394 - lr: 3.1250e-04\n",
      "Epoch 57/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3402 - accuracy: 0.8402 - val_loss: 0.3413 - val_accuracy: 0.8396 - lr: 3.1250e-04\n",
      "Epoch 58/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3401 - accuracy: 0.8402 - val_loss: 0.3412 - val_accuracy: 0.8397 - lr: 3.1250e-04\n",
      "Epoch 59/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3401 - accuracy: 0.8402 - val_loss: 0.3412 - val_accuracy: 0.8397 - lr: 3.1250e-04\n",
      "Epoch 60/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3400 - accuracy: 0.8406 - val_loss: 0.3412 - val_accuracy: 0.8396 - lr: 1.5625e-04\n",
      "Epoch 61/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3400 - accuracy: 0.8404 - val_loss: 0.3412 - val_accuracy: 0.8396 - lr: 1.5625e-04\n",
      "Epoch 62/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3400 - accuracy: 0.8403 - val_loss: 0.3412 - val_accuracy: 0.8396 - lr: 1.5625e-04\n",
      "Epoch 63/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3400 - accuracy: 0.8406 - val_loss: 0.3411 - val_accuracy: 0.8396 - lr: 1.5625e-04\n",
      "Epoch 64/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3399 - accuracy: 0.8405 - val_loss: 0.3411 - val_accuracy: 0.8397 - lr: 1.5625e-04\n",
      "Epoch 65/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3399 - accuracy: 0.8404 - val_loss: 0.3411 - val_accuracy: 0.8398 - lr: 1.5625e-04\n",
      "Epoch 66/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3399 - accuracy: 0.8404 - val_loss: 0.3411 - val_accuracy: 0.8397 - lr: 1.5625e-04\n",
      "Epoch 67/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3399 - accuracy: 0.8404 - val_loss: 0.3411 - val_accuracy: 0.8397 - lr: 1.5625e-04\n",
      "Epoch 68/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8405 - val_loss: 0.3410 - val_accuracy: 0.8397 - lr: 1.5625e-04\n",
      "Epoch 69/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8404 - val_loss: 0.3410 - val_accuracy: 0.8397 - lr: 1.5625e-04\n",
      "Epoch 70/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8406 - val_loss: 0.3410 - val_accuracy: 0.8397 - lr: 7.8125e-05\n",
      "Epoch 71/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8406 - val_loss: 0.3410 - val_accuracy: 0.8397 - lr: 7.8125e-05\n",
      "Epoch 72/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8406 - val_loss: 0.3410 - val_accuracy: 0.8397 - lr: 7.8125e-05\n",
      "Epoch 73/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8406 - val_loss: 0.3410 - val_accuracy: 0.8397 - lr: 7.8125e-05\n",
      "Epoch 74/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8406 - val_loss: 0.3410 - val_accuracy: 0.8397 - lr: 7.8125e-05\n",
      "Epoch 75/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3398 - accuracy: 0.8405 - val_loss: 0.3410 - val_accuracy: 0.8397 - lr: 7.8125e-05\n",
      "Epoch 76/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3410 - val_accuracy: 0.8398 - lr: 7.8125e-05\n",
      "Epoch 77/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3410 - val_accuracy: 0.8398 - lr: 7.8125e-05\n",
      "Epoch 78/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8407 - val_loss: 0.3409 - val_accuracy: 0.8397 - lr: 7.8125e-05\n",
      "Epoch 79/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8407 - val_loss: 0.3409 - val_accuracy: 0.8397 - lr: 7.8125e-05\n",
      "Epoch 80/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8397 - lr: 3.9062e-05\n",
      "Epoch 81/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8397 - lr: 3.9062e-05\n",
      "Epoch 82/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8407 - val_loss: 0.3409 - val_accuracy: 0.8397 - lr: 3.9062e-05\n",
      "Epoch 83/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8397 - lr: 3.9062e-05\n",
      "Epoch 84/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8407 - val_loss: 0.3409 - val_accuracy: 0.8397 - lr: 3.9062e-05\n",
      "Epoch 85/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8397 - lr: 3.9062e-05\n",
      "Epoch 86/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8397 - lr: 3.9062e-05\n",
      "Epoch 87/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 3.9062e-05\n",
      "Epoch 88/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8407 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 3.9062e-05\n",
      "Epoch 89/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 3.9062e-05\n",
      "Epoch 90/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3397 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 91/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 92/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 93/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 94/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 95/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 96/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 97/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8407 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 98/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 99/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 1.9531e-05\n",
      "Epoch 100/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3396 - accuracy: 0.8406 - val_loss: 0.3409 - val_accuracy: 0.8398 - lr: 9.7656e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f0314421c30>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_lr_2 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate,history_lr_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 100)               4200      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                510       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,771\n",
      "Trainable params: 9,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "943/943 [==============================] - 4s 3ms/step - loss: 0.3461 - accuracy: 0.8388 - val_loss: 0.3282 - val_accuracy: 0.8461 - lr: 0.0100\n",
      "Epoch 2/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3271 - accuracy: 0.8477 - val_loss: 0.3320 - val_accuracy: 0.8414 - lr: 0.0100\n",
      "Epoch 3/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3210 - accuracy: 0.8497 - val_loss: 0.3253 - val_accuracy: 0.8480 - lr: 0.0100\n",
      "Epoch 4/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3146 - accuracy: 0.8528 - val_loss: 0.3208 - val_accuracy: 0.8501 - lr: 0.0100\n",
      "Epoch 5/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.3106 - accuracy: 0.8552 - val_loss: 0.3172 - val_accuracy: 0.8517 - lr: 0.0100\n",
      "Epoch 6/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3075 - accuracy: 0.8551 - val_loss: 0.3183 - val_accuracy: 0.8515 - lr: 0.0100\n",
      "Epoch 7/100\n",
      "943/943 [==============================] - 2s 2ms/step - loss: 0.3038 - accuracy: 0.8590 - val_loss: 0.3282 - val_accuracy: 0.8519 - lr: 0.0100\n",
      "Epoch 8/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.3007 - accuracy: 0.8585 - val_loss: 0.3196 - val_accuracy: 0.8528 - lr: 0.0100\n",
      "Epoch 9/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2986 - accuracy: 0.8608 - val_loss: 0.3216 - val_accuracy: 0.8504 - lr: 0.0100\n",
      "Epoch 10/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2895 - accuracy: 0.8650 - val_loss: 0.3204 - val_accuracy: 0.8520 - lr: 0.0050\n",
      "Epoch 11/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2863 - accuracy: 0.8662 - val_loss: 0.3223 - val_accuracy: 0.8516 - lr: 0.0050\n",
      "Epoch 12/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2842 - accuracy: 0.8660 - val_loss: 0.3226 - val_accuracy: 0.8470 - lr: 0.0050\n",
      "Epoch 13/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2822 - accuracy: 0.8665 - val_loss: 0.3203 - val_accuracy: 0.8521 - lr: 0.0050\n",
      "Epoch 14/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2803 - accuracy: 0.8679 - val_loss: 0.3246 - val_accuracy: 0.8510 - lr: 0.0050\n",
      "Epoch 15/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2785 - accuracy: 0.8687 - val_loss: 0.3243 - val_accuracy: 0.8469 - lr: 0.0050\n",
      "Epoch 16/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2757 - accuracy: 0.8688 - val_loss: 0.3302 - val_accuracy: 0.8444 - lr: 0.0050\n",
      "Epoch 17/100\n",
      "943/943 [==============================] - 2s 3ms/step - loss: 0.2747 - accuracy: 0.8693 - val_loss: 0.3322 - val_accuracy: 0.8485 - lr: 0.0050\n",
      "Epoch 18/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2731 - accuracy: 0.8707 - val_loss: 0.3329 - val_accuracy: 0.8501 - lr: 0.0050\n",
      "Epoch 19/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2709 - accuracy: 0.8711 - val_loss: 0.3336 - val_accuracy: 0.8507 - lr: 0.0050\n",
      "Epoch 20/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2643 - accuracy: 0.8738 - val_loss: 0.3355 - val_accuracy: 0.8499 - lr: 0.0025\n",
      "Epoch 21/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2618 - accuracy: 0.8747 - val_loss: 0.3372 - val_accuracy: 0.8496 - lr: 0.0025\n",
      "Epoch 22/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2600 - accuracy: 0.8757 - val_loss: 0.3387 - val_accuracy: 0.8485 - lr: 0.0025\n",
      "Epoch 23/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2578 - accuracy: 0.8774 - val_loss: 0.3434 - val_accuracy: 0.8490 - lr: 0.0025\n",
      "Epoch 24/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2562 - accuracy: 0.8771 - val_loss: 0.3518 - val_accuracy: 0.8487 - lr: 0.0025\n",
      "Epoch 25/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2544 - accuracy: 0.8791 - val_loss: 0.3484 - val_accuracy: 0.8485 - lr: 0.0025\n",
      "Epoch 26/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2529 - accuracy: 0.8785 - val_loss: 0.3524 - val_accuracy: 0.8469 - lr: 0.0025\n",
      "Epoch 27/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2510 - accuracy: 0.8802 - val_loss: 0.3542 - val_accuracy: 0.8503 - lr: 0.0025\n",
      "Epoch 28/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2498 - accuracy: 0.8806 - val_loss: 0.3569 - val_accuracy: 0.8461 - lr: 0.0025\n",
      "Epoch 29/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2480 - accuracy: 0.8818 - val_loss: 0.3626 - val_accuracy: 0.8419 - lr: 0.0025\n",
      "Epoch 30/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2428 - accuracy: 0.8851 - val_loss: 0.3652 - val_accuracy: 0.8443 - lr: 0.0012\n",
      "Epoch 31/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2408 - accuracy: 0.8869 - val_loss: 0.3656 - val_accuracy: 0.8460 - lr: 0.0012\n",
      "Epoch 32/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2399 - accuracy: 0.8864 - val_loss: 0.3712 - val_accuracy: 0.8448 - lr: 0.0012\n",
      "Epoch 33/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2389 - accuracy: 0.8863 - val_loss: 0.3753 - val_accuracy: 0.8441 - lr: 0.0012\n",
      "Epoch 34/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2376 - accuracy: 0.8874 - val_loss: 0.3703 - val_accuracy: 0.8436 - lr: 0.0012\n",
      "Epoch 35/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2366 - accuracy: 0.8883 - val_loss: 0.3762 - val_accuracy: 0.8423 - lr: 0.0012\n",
      "Epoch 36/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2352 - accuracy: 0.8892 - val_loss: 0.3787 - val_accuracy: 0.8429 - lr: 0.0012\n",
      "Epoch 37/100\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.2343 - accuracy: 0.8896 - val_loss: 0.3837 - val_accuracy: 0.8384 - lr: 0.0012\n",
      "Epoch 38/100\n",
      "943/943 [==============================] - 3s 3ms/step - loss: 0.2332 - accuracy: 0.8909 - val_loss: 0.3799 - val_accuracy: 0.8407 - lr: 0.0012\n",
      "Epoch 39/100\n",
      "943/943 [==============================] - 3s 4ms/step - loss: 0.2323 - accuracy: 0.8908 - val_loss: 0.3840 - val_accuracy: 0.8396 - lr: 0.0012\n",
      "Epoch 40/100\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.2283 - accuracy: 0.8926 - val_loss: 0.3924 - val_accuracy: 0.8393 - lr: 6.2500e-04\n",
      "Epoch 41/100\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.2277 - accuracy: 0.8934 - val_loss: 0.3929 - val_accuracy: 0.8376 - lr: 6.2500e-04\n",
      "Epoch 42/100\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.2270 - accuracy: 0.8941 - val_loss: 0.3962 - val_accuracy: 0.8389 - lr: 6.2500e-04\n",
      "Epoch 43/100\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.2262 - accuracy: 0.8946 - val_loss: 0.3972 - val_accuracy: 0.8392 - lr: 6.2500e-04\n",
      "Epoch 44/100\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.2258 - accuracy: 0.8945 - val_loss: 0.3959 - val_accuracy: 0.8400 - lr: 6.2500e-04\n",
      "Epoch 45/100\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.2251 - accuracy: 0.8952 - val_loss: 0.4015 - val_accuracy: 0.8396 - lr: 6.2500e-04\n",
      "Epoch 46/100\n",
      "943/943 [==============================] - 4s 4ms/step - loss: 0.2245 - accuracy: 0.8956 - val_loss: 0.4029 - val_accuracy: 0.8379 - lr: 6.2500e-04\n",
      "Epoch 47/100\n",
      "943/943 [==============================] - 4s 5ms/step - loss: 0.2239 - accuracy: 0.8953 - val_loss: 0.4025 - val_accuracy: 0.8388 - lr: 6.2500e-04\n",
      "Epoch 48/100\n",
      "943/943 [==============================] - 5s 5ms/step - loss: 0.2234 - accuracy: 0.8963 - val_loss: 0.4021 - val_accuracy: 0.8412 - lr: 6.2500e-04\n",
      "Epoch 49/100\n",
      "943/943 [==============================] - 767s 814ms/step - loss: 0.2229 - accuracy: 0.8967 - val_loss: 0.4065 - val_accuracy: 0.8393 - lr: 6.2500e-04\n",
      "Epoch 50/100\n",
      "943/943 [==============================] - 915s 971ms/step - loss: 0.2206 - accuracy: 0.8974 - val_loss: 0.4073 - val_accuracy: 0.8405 - lr: 3.1250e-04\n",
      "Epoch 51/100\n",
      "943/943 [==============================] - 1242s 1s/step - loss: 0.2203 - accuracy: 0.8982 - val_loss: 0.4083 - val_accuracy: 0.8375 - lr: 3.1250e-04\n",
      "Epoch 52/100\n",
      "943/943 [==============================] - 1097s 1s/step - loss: 0.2200 - accuracy: 0.8981 - val_loss: 0.4118 - val_accuracy: 0.8386 - lr: 3.1250e-04\n",
      "Epoch 53/100\n",
      "809/943 [========================>.....] - ETA: 3:13 - loss: 0.2190 - accuracy: 0.8981"
     ]
    }
   ],
   "source": [
    "history_lr_3 = History()\n",
    "model = Sequential()\n",
    "model.add(Dense(100,activation=\"sigmoid\",input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(50,activation=\"sigmoid\"))\n",
    "model.add(Dense(10,activation=\"sigmoid\"))\n",
    "model.add(Dense(1,activation=\"sigmoid\"))\n",
    "model.summary()\n",
    "\n",
    "adam2 = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=adam2, metrics=[\"accuracy\"])\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "model.fit(X_train, y_train, validation_data= (X_test, y_test), batch_size=32,epochs=100, callbacks=[lrate,history_lr_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history_lr_1.history['val_accuracy'], label = \"test\")\n",
    "plt.plot(history_lr_2.history['val_accuracy'], label = \"test LR 1\")\n",
    "plt.plot(history_lr_3.history['val_accuracy'], label = \"test LR 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}